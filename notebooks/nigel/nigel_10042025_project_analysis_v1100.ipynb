{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b045b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load your dataset\n",
    "file_path = \"../../data/input/Freight_Cost_Analysis_CY2024-03.25.csv\"\n",
    "df = pd.read_csv(file_path, encoding=\"latin1\", low_memory=False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708706e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  === Load Commodity Groups ===\n",
    "# Load the commodity groups from the Excel file\n",
    "commodity_df = pd.read_excel('../../data/input/IFS Cloud Commodity Groups.xlsx', sheet_name='Commodity Groups')\n",
    "commodity_df.head()\n",
    "\n",
    "\n",
    "# Convert 'Commodity Group' to string and create a new column 'COMM 1'\n",
    "commodity_df['COMM 1'] = commodity_df['Commodity Group'].astype(str)\n",
    "\n",
    "# Convert 'Commodity Group' to string in the main DataFrame\n",
    "df['COMM 1'] = df['COMM 1'].astype(str)\n",
    "\n",
    "# Perform the join on the 'COMM 1' column\n",
    "merged_df = df.merge(commodity_df, on='COMM 1', how='left')\n",
    "# Flag matched and unmatched rows clearly\n",
    "merged_df['Match Commodity'] = merged_df['Commodity Group'].apply(\n",
    "    lambda x: 'Commodity Found' if pd.notna(x) else 'Commodity Not Found'\n",
    ")\n",
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bcc19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in the 'uom' column\n",
    "merged_df['INV UOM'] = merged_df['INV UOM'].replace({'SF': 'SQFT', 'SY': 'SQYD'})\n",
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d78be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  === Load Manufacturers ===\n",
    "# Load the manufacturers from the Excel file\n",
    "manufacturer_df = pd.read_excel('../../data/input/Manufacturer List.xlsx', sheet_name='Sheet1')\n",
    "manufacturer_df.head()\n",
    "\n",
    "# Convert 'Commodity Group' to string and create a new column 'COMM 1'\n",
    "manufacturer_df['SUPPLIER NO'] = manufacturer_df['Supplier No'].astype(str)\n",
    "manufacturer_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b0cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert 'Commodity Group' to string in the main DataFrame\n",
    "merged_df['SUPPLIER NO'] = merged_df['SUPPLIER NO'].astype(str)\n",
    "# Perform the join on the 'COMM 1' column\n",
    "merged_df2 = merged_df.merge(manufacturer_df[['SUPPLIER NO','Supplier Name']], on='SUPPLIER NO', how='left')\n",
    "\n",
    "merged_df2['Match Supplier'] = merged_df2['Supplier Name'].apply(\n",
    "    lambda x: 'Supplier registered' if pd.notna(x) else 'No supplier found'\n",
    ")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "merged_df2.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f0d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning function to standardise the description conversion\n",
    "# This function will classify the commodity based on the description\n",
    "def classify_commodity(row):\n",
    "    desc = str(row['Description'])\n",
    "    desc_lower = desc.lower()\n",
    "    \n",
    "    if 'vinyl' in desc_lower:\n",
    "        return ''.join(filter(str.isalpha, str(row['COMM 2'])))\n",
    "    elif 'carpet' in desc_lower:\n",
    "        if desc_lower == 'carpet bl':\n",
    "            return 'Carpet Roll'\n",
    "        elif desc_lower == 'carpet tile':\n",
    "            return 'Carpet Tiles'\n",
    "        else:\n",
    "            return 'Carpet Roll'\n",
    "    else:\n",
    "        return desc  # Default: keep original Description\n",
    "\n",
    "# Apply to new column\n",
    "merged_df2['new commodity description'] = merged_df2.apply(classify_commodity, axis=1)\n",
    "# Display the updated DataFrame\n",
    "merged_df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade86dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will classify the commodity from old codes to new codes\n",
    "def map_commodity_group(x):\n",
    "    x_str = str(x)\n",
    "    \n",
    "    if '10' in x_str:\n",
    "        return '1CBL'\n",
    "    elif x_str == '100':\n",
    "        return '1CPT'\n",
    "    elif x_str == '40':\n",
    "        return '1VNL'\n",
    "    else:\n",
    "        return x  # Keep original value if none of the above match\n",
    "\n",
    "# Apply the function to update the column\n",
    "merged_df2['new commodity group'] = merged_df2['Commodity Group'].apply(map_commodity_group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ba1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display the updated DataFrame\n",
    "merged_df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df2['new commodity description'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c91f8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this point df becomes default DB\n",
    "# Set the DataFrame to merged_df2 for further processing\n",
    "df = merged_df2\n",
    "\n",
    "# Normalize the 'INV UOM' column to handle case sensitivity and strip spaces\n",
    "df['INV UOM'] = df['INV UOM'].str.strip().str.upper()\n",
    "\n",
    "# Classify rows based on 'INV UOM' values\n",
    "df['Classification'] = df.apply(\n",
    "    lambda row: 'Classified' if row['INV UOM'] in ['SQFT', 'SQYD']\n",
    "    else ('No UOM' if pd.isna(row['INV UOM']) or row['INV UOM'] == '' else 'Unclassified'),\n",
    "    axis=1\n",
    ")\n",
    "# Create a new column 'conversion_code' based on the 'Description' + 'Comodity Group' + 'INV UOM' column\n",
    "df['conversion_code'] = df['new commodity description'].str.replace(' ', '_', regex=True).astype(str) + '_' + df['new commodity group'].astype(str) + '_' + df['INV UOM'].astype(str)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which of the rows in an invoice matching 2008 has unclassified items\n",
    "# Check if all rows with ACCOUNT == 2008 are classified\n",
    "# Step 1: Identify invoice IDs where ALL rows with ACCOUNT == 2008 are classified\n",
    "classified_invoice_ids = (\n",
    "    df[df['ACCOUNT'] == 2008]\n",
    "    .groupby('INVOICE ID')['Classification']\n",
    "    .apply(lambda x: all(x == 'Classified'))\n",
    ")\n",
    "\n",
    "# Step 2: Filter to only invoice IDs where ALL 2008 accounts are classified\n",
    "fully_classified_ids = classified_invoice_ids[classified_invoice_ids].index\n",
    "\n",
    "# Step 3: Create a new column to mark if entire invoice is considered classified (based on the 2008 rule)\n",
    "df['All Accounts 2008 Classified'] = df['INVOICE ID'].isin(fully_classified_ids)\n",
    "\n",
    "# Step 4: Count how many invoices meet this condition\n",
    "count_all_classified_invoices = df[df['All Accounts 2008 Classified']]['INVOICE ID'].nunique()\n",
    "\n",
    "print(f\"Number of invoices where all ACCOUNT == 2008 are classified: {count_all_classified_invoices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking which of the rows in an invoice matching 2008 has existing conversion codes to area\n",
    "# Step 1: Identify invoice IDs where ALL rows with ACCOUNT == 2008 have existing conversion codes\n",
    "# 1. Load the rates table\n",
    "rates_df = pd.read_csv('../../app/conversion_table_standardized.csv')  # adjust path and filename\n",
    "# Step 1: Ensure consistent data types\n",
    "rates_df['conversion_code'] = rates_df['conversion_code'].astype(str)\n",
    "df['conversion_code'] = df['conversion_code'].astype(str)\n",
    "\n",
    "# Step 2: Create a set of valid conversion codes from the rates table\n",
    "valid_codes = set(rates_df['conversion_code'].unique())\n",
    "\n",
    "# Step 3: Filter only rows with ACCOUNT == 2008\n",
    "df_2008 = df[df['ACCOUNT'] == 2008].copy()\n",
    "\n",
    "# Step 4: For each INVOICE ID, check if all conversion codes for ACCOUNT 2008 are valid\n",
    "invoice_validity = df_2008.groupby('INVOICE ID')['conversion_code'].apply(\n",
    "    lambda codes: all(code in valid_codes for code in codes)\n",
    ")\n",
    "\n",
    "# Step 5: Get list of INVOICE IDs where all ACCOUNT 2008 codes are valid\n",
    "fully_valid_invoice_ids = invoice_validity[invoice_validity].index\n",
    "\n",
    "# Step 6: Create a new column in the main df that flags all rows for those invoices\n",
    "df['All 2008 Accounts Converted'] = df['INVOICE ID'].isin(fully_valid_invoice_ids)\n",
    "\n",
    "# Step 7: Count how many invoices meet this condition\n",
    "count_all_valid_invoices = df[df['All 2008 Accounts Converted']]['INVOICE ID'].nunique()\n",
    "\n",
    "print(f\"Number of invoices where all ACCOUNT == 2008 have valid conversion codes: {count_all_valid_invoices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0600c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get INVOICE IDs that have at least one freight line (ACCOUNT == 5504)\n",
    "freight_invoice_ids = df[df['ACCOUNT'] == 5504]['INVOICE ID'].unique()\n",
    "\n",
    "# Step 2: Flag all rows where the INVOICE ID appears in that list\n",
    "df['Has Freight Line'] = df['INVOICE ID'].isin(freight_invoice_ids)\n",
    "# Step 3: Count how many invoices have at least one freight line\n",
    "count_freight_invoices = df[df['Has Freight Line']]['INVOICE ID'].nunique()\n",
    "\n",
    "print(f\"Number of invoices with at least one freight line: {count_freight_invoices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba38be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Group by INVOICE ID and count the number of rows where ACCOUNT == 5504\n",
    "freight_count = df[df['ACCOUNT'] == 5504].groupby('INVOICE ID').size()\n",
    "\n",
    "# Flag invoices with more than 1 Project Freight line item\n",
    "df['Multiple Freight Lines'] = df['INVOICE ID'].map(freight_count > 1).fillna(False)\n",
    "# Step 4: Count how many invoices have multiple freight lines\n",
    "count_multiple_freight_invoices = df[df['Multiple Freight Lines']]['INVOICE ID'].nunique()\n",
    "\n",
    "print(f\"Number of invoices with multiple freight lines: {count_multiple_freight_invoices}\")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75198a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter the DataFrame to only include rows where ACCOUNT == 2008\n",
    "# These represent \"Part Component\" line items we're interested in\n",
    "df_2008 = df[df['ACCOUNT'] == 2008]\n",
    "\n",
    "# Step 2: Group by INVOICE ID and count the number of distinct partnumbers per invoice\n",
    "# This tells us how many unique parts are associated with each invoice\n",
    "component_count = df_2008.groupby('INVOICE ID')['PART NO'].nunique()\n",
    "\n",
    "# Step 3: Create a new column 'Multiple Parts' in the main DataFrame\n",
    "# For each INVOICE ID, mark True if it has more than one unique partnumber; otherwise False\n",
    "# Invoices without any ACCOUNT == 2008 lines will get NaN, so we fill those with False\n",
    "df['Multiple Parts'] = df['INVOICE ID'].map(component_count > 1).fillna(False)\n",
    "\n",
    "# Step 4: Count how many invoices have multiple distinct part components\n",
    "count_multiple_parts_invoices = df[df['Multiple Parts']]['INVOICE ID'].nunique()\n",
    "\n",
    "# Step 5: Print the result for quick validation\n",
    "print(f\"Number of invoices with multiple distinct parts: {count_multiple_parts_invoices}\")\n",
    "\n",
    "# Step 6: Preview the updated DataFrame\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a93b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter to ACCOUNT == 2008\n",
    "df_2008 = df[df['ACCOUNT'] == 2008]\n",
    "\n",
    "# Step 2: For each invoice, check if all rows with ACCOUNT == 2008 have Priority == 'Yes'\n",
    "priority_flag = df_2008.groupby('INVOICE ID')['Priority'].apply(\n",
    "    lambda x: all(x == 'Yes')\n",
    ")\n",
    "\n",
    "# Step 3: Get invoice IDs where all ACCOUNT 2008 rows have Priority == 'Yes'\n",
    "priority_invoice_ids = priority_flag[priority_flag].index\n",
    "\n",
    "# Step 4: Flag those invoice IDs across the full dataframe\n",
    "df['All Priority Products (2008)'] = df['INVOICE ID'].isin(priority_invoice_ids)   \n",
    "# Step 5: Count how many invoices meet this condition\n",
    "count_priority_invoices = df[df['All Priority Products (2008)']]['INVOICE ID'].nunique()\n",
    "\n",
    "# Step 6: Print the result for quick validation\n",
    "print(f\"Number of invoices where all ACCOUNT == 2008 have Priority == 'Yes': {count_priority_invoices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2455389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True if at least one ACCOUNT == 2008 line in the invoice has Priority == 'Yes'\n",
    "priority_flag_any = df_2008.groupby('INVOICE ID')['Priority'].apply(lambda x: any(x == 'Yes'))\n",
    "priority_invoice_ids_any = priority_flag_any[priority_flag_any].index\n",
    "df['Any Priority Product (2008)'] = df['INVOICE ID'].isin(priority_invoice_ids_any)\n",
    "# Step 5: Count how many invoices meet this condition\n",
    "count_any_priority_invoices = df[df['Any Priority Product (2008)']]['INVOICE ID'].nunique()\n",
    "\n",
    "# Step 6: Print the result for quick validation\n",
    "print(f\"Number of invoices where at least one ACCOUNT == 2008 has Priority == 'Yes': {count_any_priority_invoices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0bb157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template_columns = ['PROJECT ID','PROJECT NAME','PO NO','ACCOUNT', 'ACCOUNT DESCRIPTION',\n",
    "                     'SITE','SITE DESCRIPTION',\n",
    "                     'SUPPLIER NO', 'SUPPLIER NAME', \n",
    "                     'PART NO', 'PART DESCRIPTION',\n",
    "                    'INVOICED LINE QTY','INVOICE ID',\n",
    "                    'INVOICE NO','INV UOM','COMM 1','COMM 2',\n",
    "                    'Commodity Group', 'Description',\n",
    "                    'Old/New', 'Priority', 'Classification',\n",
    "                    'conversion_code','INVOICE LINE TOTAL',\n",
    "                    'Has Freight Line','Multiple Freight Lines',\n",
    "                    'Multiple Parts','All Priority Products (2008)',\n",
    "                    'Any Priority Product (2008)','Match Commodity','Match Supplier','new commodity description',\n",
    "                    'new commodity group','All Accounts 2008 Classified','All 2008 Accounts Converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b8cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping of template columns to the desired column names\n",
    "column_mapping = {\n",
    "    \n",
    "    'PROJECT ID':'project_id',\n",
    "    'PROJECT NAME':'project_name',\n",
    "    'PO NO': 'po_no',\n",
    "    'INVOICE ID': 'invoice_id',\n",
    "    'INVOICE NO': 'invoice_no',\n",
    "    'ACCOUNT':'account', \n",
    "    'ACCOUNT DESCRIPTION':'account_description',\n",
    "    'SITE': 'siteid',\n",
    "    'SITE DESCRIPTION': 'site',\n",
    "    'SUPPLIER NO': 'supplierid',\n",
    "    'SUPPLIER NAME': 'suppliername',\n",
    "    'INVOICED LINE QTY': 'quantity',\n",
    "    'PART NO': 'partnumber',\n",
    "    'PART DESCRIPTION':'partdescription',\n",
    "    'COMM 1': 'comm1',\n",
    "    'COMM 2': 'comm2',\n",
    "    'Commodity Group': 'commodity_group',\n",
    "    'Description': 'commoditydescription',\n",
    "    'INV UOM': 'uom',\n",
    "    'Priority':'priority', \n",
    "    'Classification': 'classification',\n",
    "    'conversion_code': 'conversion_code',\n",
    "    'Old/New': 'old_new',\n",
    "    'Has Freight Line':'freight_invoice',\n",
    "    'INVOICE LINE TOTAL': 'invoice_line_total',\n",
    "    'Multiple Freight Lines':'multiple_freight_lines',\n",
    "    'Multiple Parts':'multiple_parts',\n",
    "    'All Priority Products (2008)':'all_priority_products',\n",
    "    'Any Priority Product (2008)':'any_priority_products',\n",
    "    'Match Commodity':'match_commodity',\n",
    "    'Match Supplier':'match_supplier',\n",
    "    'new commodity description':'new_commodity_description',\n",
    "    'new commodity group':'new_commodity_group',\n",
    "    'All Accounts 2008 Classified':'all_accounts_2008_classified',\n",
    "    'All 2008 Accounts Converted':'all_2008_accounts_converted'\n",
    "}\n",
    "\n",
    "# Rename the columns in the DataFrame\n",
    "mapped_df = df[template_columns].rename(columns=column_mapping)\n",
    "\n",
    "# Display the first few rows of the mapped DataFrame\n",
    "mapped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by ACCOUNT and ACCOUNT DESCRIPTION, and count unique INVOICE IDs\n",
    "account_summary = mapped_df.groupby(['account', 'account_description'])['invoice_id'].nunique()\n",
    "\n",
    "# Convert the result to a DataFrame for better readability\n",
    "account_summary = account_summary.reset_index(name='Unique Invoice Count').sort_values('Unique Invoice Count', ascending=False)\n",
    "\n",
    "# Display the summary\n",
    "account_summary.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc2d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by ACCOUNT and ACCOUNT DESCRIPTION, and count unique INVOICE IDs\n",
    "project_freight_df = mapped_df[mapped_df['freight_invoice'] == True]\n",
    "\n",
    "account_summary = project_freight_df.groupby(['account', 'account_description'])['invoice_id'].nunique()\n",
    "\n",
    "# Convert the result to a DataFrame for better readability\n",
    "account_summary = account_summary.reset_index(name='Unique Invoice Count').sort_values('Unique Invoice Count', ascending=False)\n",
    "\n",
    "# Display the summary\n",
    "account_summary.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e04576",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_invoices = mapped_df['invoice_id'].nunique()\n",
    "print(f\"Unique Invoices in mapped_df: {unique_invoices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8f55f",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Get records with product IDs\n",
    "mapped_df = mapped_df[mapped_df['project_id'].notna()]\n",
    "mapped_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe2c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_invoices = mapped_df['invoice_id'].nunique()\n",
    "print(f\"Unique Invoices in mapped_df: {unique_invoices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07155d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = mapped_df[mapped_df['po_no'].notna()]\n",
    "unique_invoice_ids_with_po_no = filtered_df['invoice_id'].nunique()\n",
    "print(f\"Unique Invoice IDs with PO NO: {unique_invoice_ids_with_po_no}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1020fd7",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Filter rows where 'po_no' is not null and 'all_priority_products' is True\n",
    "freight_filtered_df = filtered_df[filtered_df['freight_invoice'] == True]\n",
    "\n",
    "# Calculate the unique invoice IDs\n",
    "unique_priority_invoice_ids = freight_filtered_df['invoice_id'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Unique Invoice IDs with PO NO and Freight Price = True: {unique_priority_invoice_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a17cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'po_no' is not null and 'all_priority_products' is True\n",
    "priority_filtered_df = freight_filtered_df[freight_filtered_df['any_priority_products'] == True]\n",
    "\n",
    "# Calculate the unique invoice IDs\n",
    "unique_priority_invoice_ids = priority_filtered_df['invoice_id'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Unique Invoice IDs with PO NO ,Freight and Any Priority Products = True: {unique_priority_invoice_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'po_no' is not null and 'all_priority_products' is True\n",
    "all_priority_filtered_df = freight_filtered_df[freight_filtered_df['all_priority_products'] == True]\n",
    "\n",
    "# Calculate the unique invoice IDs\n",
    "unique_priority_invoice_ids = all_priority_filtered_df['invoice_id'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Unique Invoice IDs with PO NO ,Freight and All Priority Products = True: {unique_priority_invoice_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5a266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'po_no' is not null and 'all_priority_products' is True\n",
    "priority_filtered_df = all_priority_filtered_df[all_priority_filtered_df['all_classified'] == True]\n",
    "\n",
    "# Calculate the unique invoice IDs\n",
    "unique_priority_invoice_ids = priority_filtered_df['invoice_id'].nunique()\n",
    "\n",
    "# Print the result\n",
    "print(f\"Unique Invoice IDs with PO NO ,Freight and All Priority Products and all classified = True: {unique_priority_invoice_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da3ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "mapped_df.to_csv(f'../../data/output/enhanced_data_{timestamp}.csv', index=False)\n",
    "# Display the first few rows of the filtered DataFrame  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e07c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79dfb818",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
